[druid] 2018-11-02 19:35:21,904 [main           ] WARN  rg.apache.hadoop.fs.FileSystem {1} - "hdfs:hadoop01:9000" is a deprecated filesystem name. Use "hdfs://hdfs:hadoop01:9000/" instead.
   [druid] 2018-11-02 19:35:21,962 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-02 19:35:21,965 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-02 19:35:21,978 [main           ] WARN  rg.apache.hadoop.fs.FileSystem {1} - "hdfs:hadoop01:9000" is a deprecated filesystem name. Use "hdfs://hdfs:hadoop01:9000/" instead.
   [druid] 2018-11-02 19:35:59,384 [main           ] WARN  rg.apache.hadoop.fs.FileSystem {1} - "hdfs:hadoop01:9000" is a deprecated filesystem name. Use "hdfs://hdfs:hadoop01:9000/" instead.
   [druid] 2018-11-02 19:35:59,387 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-02 19:35:59,388 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-02 19:35:59,395 [main           ] WARN  rg.apache.hadoop.fs.FileSystem {1} - "hdfs:hadoop01:9000" is a deprecated filesystem name. Use "hdfs://hdfs:hadoop01:9000/" instead.
   [druid] 2018-11-02 19:35:59,576 [main           ] WARN  rg.apache.hadoop.fs.FileSystem {1} - "hdfs:hadoop01:9000" is a deprecated filesystem name. Use "hdfs://hdfs:hadoop01:9000/" instead.
   [druid] 2018-11-02 19:35:59,692 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Cleaning up the staging area file:/home/hadoop/hadoop-2.6.0/data/mapred/staging/lenovo64482028/.staging/job_local64482028_0001
   [druid] 2018-11-02 19:48:16,955 [main           ] WARN  rg.apache.hadoop.fs.FileSystem {1} - "hdfs:hadoop01:9000" is a deprecated filesystem name. Use "hdfs://hdfs:hadoop01:9000/" instead.
   [druid] 2018-11-02 19:48:17,031 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-02 19:48:17,033 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-02 19:48:17,044 [main           ] WARN  rg.apache.hadoop.fs.FileSystem {1} - "hdfs:hadoop01:9000" is a deprecated filesystem name. Use "hdfs://hdfs:hadoop01:9000/" instead.
   [druid] 2018-11-02 19:48:17,378 [main           ] WARN  rg.apache.hadoop.fs.FileSystem {1} - "hdfs:hadoop01:9000" is a deprecated filesystem name. Use "hdfs://hdfs:hadoop01:9000/" instead.
   [druid] 2018-11-02 19:48:17,480 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Cleaning up the staging area file:/home/hadoop/hadoop-2.6.0/data/mapred/staging/lenovo191583090/.staging/job_local191583090_0001
   [druid] 2018-11-02 19:54:42,704 [main           ] WARN  rg.apache.hadoop.fs.FileSystem {1} - "hdfs:hadoop01:9000" is a deprecated filesystem name. Use "hdfs://hdfs:hadoop01:9000/" instead.
   [druid] 2018-11-02 19:55:10,677 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-02 19:55:10,679 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-02 19:55:23,528 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-02 19:55:23,604 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-02 19:55:24,340 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-02 19:55:24,599 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-02 19:55:24,858 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1822138215_0001
   [druid] 2018-11-02 19:55:25,233 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-02 19:55:25,234 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1822138215_0001
   [druid] 2018-11-02 19:55:25,237 [Thread-5       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-02 19:55:25,245 [Thread-5       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-02 19:55:25,252 [Thread-5       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-02 19:55:25,391 [Thread-5       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-02 19:55:25,391 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1822138215_0001_m_000000_0
   [druid] 2018-11-02 19:55:25,483 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-02 19:55:25,548 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-02 19:55:25,693 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@743f4c9
   [druid] 2018-11-02 19:55:25,699 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:9000/logs/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-02 19:55:25,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-02 19:55:25,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-02 19:55:25,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-02 19:55:25,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-02 19:55:25,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-02 19:55:25,839 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-02 19:55:26,238 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1822138215_0001 running in uber mode : false
   [druid] 2018-11-02 19:55:26,262 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-11-02 19:55:26,766 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-02 19:55:26,791 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-02 19:55:26,792 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-02 19:55:26,792 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1049; bufvoid = 104857600
   [druid] 2018-11-02 19:55:26,792 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-02 19:55:26,894 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-02 19:55:26,916 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1822138215_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-02 19:55:26,964 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-02 19:55:26,964 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1822138215_0001_m_000000_0' done.
   [druid] 2018-11-02 19:55:26,964 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1822138215_0001_m_000000_0
   [druid] 2018-11-02 19:55:26,965 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1822138215_0001_m_000001_0
   [druid] 2018-11-02 19:55:26,966 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-02 19:55:26,970 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-02 19:55:27,170 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@15a5df1f
   [druid] 2018-11-02 19:55:27,175 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:9000/logs/BC-22.1541082494914.log:0+494
   [druid] 2018-11-02 19:55:27,238 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-02 19:55:27,238 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-02 19:55:27,238 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-02 19:55:27,238 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-02 19:55:27,238 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-02 19:55:27,239 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-02 19:55:27,265 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-11-02 19:55:27,279 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-02 19:55:27,280 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-02 19:55:27,280 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-02 19:55:27,280 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 349; bufvoid = 104857600
   [druid] 2018-11-02 19:55:27,280 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-02 19:55:27,288 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-02 19:55:27,317 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1822138215_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-02 19:55:27,324 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-02 19:55:27,324 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1822138215_0001_m_000001_0' done.
   [druid] 2018-11-02 19:55:27,324 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1822138215_0001_m_000001_0
   [druid] 2018-11-02 19:55:27,324 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1822138215_0001_m_000002_0
   [druid] 2018-11-02 19:55:27,325 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-02 19:55:27,326 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-02 19:55:27,520 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@129861c4
   [druid] 2018-11-02 19:55:27,523 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:9000/logs/BC-22.1541082381665.log:0+455
   [druid] 2018-11-02 19:55:27,591 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-02 19:55:27,591 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-02 19:55:27,591 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-02 19:55:27,591 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-02 19:55:27,591 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-02 19:55:27,591 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-02 19:55:29,238 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-02 19:55:29,238 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-02 19:55:29,238 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-02 19:55:29,238 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 351; bufvoid = 104857600
   [druid] 2018-11-02 19:55:29,238 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-02 19:55:29,265 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 67% reduce 0%
   [druid] 2018-11-02 19:55:29,304 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-02 19:55:29,308 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1822138215_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-02 19:55:29,325 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-02 19:55:29,326 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1822138215_0001_m_000002_0' done.
   [druid] 2018-11-02 19:55:29,326 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1822138215_0001_m_000002_0
   [druid] 2018-11-02 19:55:29,326 [Thread-5       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-02 19:55:29,697 [Thread-5       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-02 19:55:29,698 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1822138215_0001_r_000000_0
   [druid] 2018-11-02 19:55:29,716 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-02 19:55:29,717 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-02 19:55:30,244 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6a4439a1
   [druid] 2018-11-02 19:55:30,265 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-11-02 19:55:30,784 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@75bdddb5
   [druid] 2018-11-02 19:55:32,573 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-02 19:55:32,575 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1822138215_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-02 19:55:32,618 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1822138215_0001_m_000001_0 decomp: 355 len: 359 to MEMORY
   [druid] 2018-11-02 19:55:34,176 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 355 bytes from map-output for attempt_local1822138215_0001_m_000001_0
   [druid] 2018-11-02 19:55:34,179 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 355, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->355
   [druid] 2018-11-02 19:55:34,227 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1822138215_0001_m_000000_0 decomp: 1063 len: 1067 to MEMORY
   [druid] 2018-11-02 19:55:34,228 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1063 bytes from map-output for attempt_local1822138215_0001_m_000000_0
   [druid] 2018-11-02 19:55:34,228 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1063, inMemoryMapOutputs.size() -> 2, commitMemory -> 355, usedMemory ->1418
   [druid] 2018-11-02 19:55:34,233 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1822138215_0001_m_000002_0 decomp: 357 len: 361 to MEMORY
   [druid] 2018-11-02 19:55:34,235 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 357 bytes from map-output for attempt_local1822138215_0001_m_000002_0
   [druid] 2018-11-02 19:55:34,235 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 357, inMemoryMapOutputs.size() -> 3, commitMemory -> 1418, usedMemory ->1775
   [druid] 2018-11-02 19:55:34,237 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-02 19:55:34,239 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-02 19:55:34,239 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-02 19:55:34,788 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-02 19:55:34,789 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 1763 bytes
   [druid] 2018-11-02 19:55:34,830 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 1775 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-02 19:55:34,832 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 1775 bytes from disk
   [druid] 2018-11-02 19:55:34,833 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-02 19:55:34,833 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-02 19:55:34,834 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1767 bytes
   [druid] 2018-11-02 19:55:34,834 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-02 19:55:35,059 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-02 19:55:35,996 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1822138215_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-02 19:55:36,003 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-02 19:55:36,003 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1822138215_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-02 19:55:36,024 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1822138215_0001_r_000000_0' to hdfs://hadoop01:9000/out/_temporary/0/task_local1822138215_0001_r_000000
   [druid] 2018-11-02 19:55:36,025 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-02 19:55:36,025 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1822138215_0001_r_000000_0' done.
   [druid] 2018-11-02 19:55:36,025 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1822138215_0001_r_000000_0
   [druid] 2018-11-02 19:55:36,025 [Thread-5       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-02 19:55:36,270 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-02 19:55:36,271 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1822138215_0001 completed successfully
   [druid] 2018-11-02 19:55:36,313 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=7167
		FILE: Number of bytes written=1153394
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=8280
		HDFS: Number of bytes written=1739
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=1749
		Map output materialized bytes=1787
		Input split bytes=342
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1787
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=1674051584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=1739
   [druid] 2018-11-02 19:58:33,598 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-02 19:58:33,600 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-02 19:58:34,034 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-02 19:58:34,089 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-02 19:58:34,232 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-02 19:58:34,275 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-02 19:58:34,409 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local2088710010_0001
   [druid] 2018-11-02 19:58:34,640 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-02 19:58:34,641 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local2088710010_0001
   [druid] 2018-11-02 19:58:34,645 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-02 19:58:34,652 [Thread-4       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-02 19:58:34,654 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-02 19:58:34,720 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-02 19:58:34,722 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2088710010_0001_m_000000_0
   [druid] 2018-11-02 19:58:34,752 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-02 19:58:34,760 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-02 19:58:34,810 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@324ed497
   [druid] 2018-11-02 19:58:34,816 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:9000/logs/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-02 19:58:35,310 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-02 19:58:35,544 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2088710010_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-02 19:58:35,559 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-02 19:58:35,559 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local2088710010_0001_m_000000_0 is allowed to commit now
   [druid] 2018-11-02 19:58:35,572 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local2088710010_0001_m_000000_0' to hdfs://hadoop01:9000/out/_temporary/0/task_local2088710010_0001_m_000000
   [druid] 2018-11-02 19:58:35,573 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-02 19:58:35,573 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2088710010_0001_m_000000_0' done.
   [druid] 2018-11-02 19:58:35,573 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2088710010_0001_m_000000_0
   [druid] 2018-11-02 19:58:35,573 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2088710010_0001_m_000001_0
   [druid] 2018-11-02 19:58:35,574 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-02 19:58:35,575 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-02 19:58:35,622 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@20defbd5
   [druid] 2018-11-02 19:58:35,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:9000/logs/BC-22.1541082494914.log:0+494
   [druid] 2018-11-02 19:58:35,644 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2088710010_0001 running in uber mode : false
   [druid] 2018-11-02 19:58:35,645 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-02 19:58:35,645 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-11-02 19:58:35,669 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2088710010_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-02 19:58:35,672 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-02 19:58:35,672 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local2088710010_0001_m_000001_0 is allowed to commit now
   [druid] 2018-11-02 19:58:35,683 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local2088710010_0001_m_000001_0' to hdfs://hadoop01:9000/out/_temporary/0/task_local2088710010_0001_m_000001
   [druid] 2018-11-02 19:58:35,684 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-02 19:58:35,684 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2088710010_0001_m_000001_0' done.
   [druid] 2018-11-02 19:58:35,684 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2088710010_0001_m_000001_0
   [druid] 2018-11-02 19:58:35,684 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2088710010_0001_m_000002_0
   [druid] 2018-11-02 19:58:35,685 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-02 19:58:35,686 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-02 19:58:35,729 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5d4d5347
   [druid] 2018-11-02 19:58:35,732 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:9000/logs/BC-22.1541082381665.log:0+455
   [druid] 2018-11-02 19:58:35,747 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-02 19:58:35,912 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2088710010_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-02 19:58:35,916 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-02 19:58:35,917 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local2088710010_0001_m_000002_0 is allowed to commit now
   [druid] 2018-11-02 19:58:36,256 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local2088710010_0001_m_000002_0' to hdfs://hadoop01:9000/out/_temporary/0/task_local2088710010_0001_m_000002
   [druid] 2018-11-02 19:58:36,257 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-02 19:58:36,257 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2088710010_0001_m_000002_0' done.
   [druid] 2018-11-02 19:58:36,257 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2088710010_0001_m_000002_0
   [druid] 2018-11-02 19:58:36,257 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-02 19:58:36,651 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2088710010_0001 completed successfully
   [druid] 2018-11-02 19:58:36,665 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 20
	File System Counters
		FILE: Number of bytes read=2361
		FILE: Number of bytes written=857898
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5859
		HDFS: Number of bytes written=4172
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=15
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Input split bytes=342
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=528482304
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=1739
   