1.创建hive表映射每一天的数据,创建分区表
create table if not exists dw_dp(
s_time bigint,
pl string,
p_url string,
u_ud string,
u_sd string
)
partitioned by(month string,day string)
row format delimited
fields terminated by '\001'
stored as orc
;
2.通过logs表将数据导入dw_en
from logs
insert into table dw_dp partition(month='11',day='06')
select s_time,pl,p_url,u_ud,u_sd
where month = '11'
and day = '06'
and en = 'e_pv'
;
3.创建临时表
create table if not exists dwa_dp(
pl string,
dt string,
col string,
ct int
)
;
数据例子:
1 1 123 1
最终临时表
CREATE TABLE if not exists stats_view_depth(
  `platform_dimension_id` int,
  `data_dimension_id` int,
  `kpi_dimension_id` int,
  `pv1` int,
  `pv2` int,
  `pv3` int,
  `pv4` int,
  `pv5_10` int,
  `pv10_30` int,
  `pv30_60` int,
  `pv60plass` int,
  `created` string
);
4.查询将数据导入dwa_dp临时表
from (
select
from_unixtime(cast(dd.s_time/1000 as bigint),"yyyy-MM-dd") dt,
dd.pl pl,
(case
when count(dd.p_url) = 1 then 'pv1'
when count(dd.p_url) = 2 then 'pv2'
when count(dd.p_url) = 3 then 'pv3'
when count(dd.p_url) = 4 then 'pv4'
when count(dd.p_url) <= 10 then 'pv5_10'
when count(dd.p_url) <= 30 then 'pv10_30'
when count(dd.p_url) <= 60 then 'pv30_60'
else 'pv60plass'
end)as pv,
dd.u_ud u_ud
from dw_dp dd
where dd.pl is not null
and dd.p_url is not null
and dd.month = '11'
and dd.day = '06'
group by pl,from_unixtime(cast(dd.s_time/1000 as bigint),"yyyy-MM-dd"),u_ud
)as tmp
insert overwrite table dwa_dp
select pl,dt,pv,count(u_ud)
group by pl,dt,pv
;
5.扩展all维度,并且数据导入最终结果表
with tmp as(
select pl as pl,dt,ct as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv1' union all
select pl as pl,dt,0 as pv1,ct as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv2' union all
select pl as pl,dt,0 as pv1,0 as pv2,ct as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv3' union all
select pl as pl,dt,0 as pv1,0 as pv2,0 as pv3,ct as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv4' union all
select pl as pl,dt,0 as pv1,0 as pv2,0 as pv3,0 as pv4,ct as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv5_10' union all
select pl as pl,dt,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,ct as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv10_30' union all
select pl as pl,dt,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,ct as pv30_60,0 as pv60plass from dwa_dp where col = 'pv30_60' union all
select pl as pl,dt,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,ct as pv60plass from dwa_dp where col = 'pv60plass' union all
select 'all' as pl,dt,ct as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv1' union all
select 'all' as pl,dt,0 as pv1,ct as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv2' union all
select 'all' as pl,dt,0 as pv1,0 as pv2,ct as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv3' union all
select 'all' as pl,dt,0 as pv1,0 as pv2,0 as pv3,ct as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv4' union all
select 'all' as pl,dt,0 as pv1,0 as pv2,0 as pv3,0 as pv4,ct as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv5_10' union all
select 'all' as pl,dt,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,ct as pv10_30,0 as pv30_60,0 as pv60plass from dwa_dp where col = 'pv10_30' union all
select 'all' as pl,dt,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,ct as pv30_60,0 as pv60plass from dwa_dp where col = 'pv30_60' union all
select 'all' as pl,dt,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,ct as pv60plass from dwa_dp where col = 'pv60plass'
)
from tmp
insert overwrite table stats_view_depth
select date_convert(dt),platform_convert(pl),2,sum(pv1),sum(pv2),sum(pv3),sum(pv4),sum(pv5_10),sum(pv10_30),sum(pv30_60),sum(pv60plass),dt
group by pl,dt
;
5.用sqoop将最终结果导入mysql数据库
查找路径
show create table stats_view_depth
执行sqoop命令
sqoop export --connect jdbc:mysql://hadoop01:3306/result \
--username hadoop --password hadoop --table stats_view_depth \
--export-dir hdfs://hadoop01:9000/user/hive/warehouse/pv.db/stats_view_depth/* \
--input-fields-terminated-by '\001' \
--update-key platform_dimension_id,date_dimension_id,kpi_dimension_id \
--update-mode allowinsert \
;


