[druid] 2018-11-01 16:46:59,317 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 16:46:59,319 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 16:48:16,248 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 16:48:16,249 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 16:50:18,967 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 16:50:18,969 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:00:09,444 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:00:09,446 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:00:09,718 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 17:00:09,778 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 17:00:09,981 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 17:00:10,037 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 17:00:10,319 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local697544192_0001
   [druid] 2018-11-01 17:00:10,640 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 17:00:10,641 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local697544192_0001
   [druid] 2018-11-01 17:00:10,653 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 17:00:10,659 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:00:10,662 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 17:00:10,748 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 17:00:10,752 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local697544192_0001_m_000000_0
   [druid] 2018-11-01 17:00:10,786 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:00:10,794 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:00:10,836 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@56e1cde4
   [druid] 2018-11-01 17:00:10,844 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 17:00:10,928 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:00:10,928 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:00:10,928 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:00:10,928 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:00:10,928 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:00:10,931 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:00:10,945 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:00:10,968 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local697544192_0001_m_000001_0
   [druid] 2018-11-01 17:00:10,972 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:00:10,972 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:00:11,020 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6da6a7da
   [druid] 2018-11-01 17:00:11,024 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 17:00:11,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:00:11,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:00:11,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:00:11,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:00:11,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:00:11,088 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:00:11,090 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:00:11,101 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local697544192_0001_m_000002_0
   [druid] 2018-11-01 17:00:11,102 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:00:11,102 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:00:11,144 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5b0ba22
   [druid] 2018-11-01 17:00:11,146 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 17:00:11,219 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:00:11,219 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:00:11,219 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:00:11,219 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:00:11,219 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:00:11,220 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:00:11,223 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:00:11,267 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 17:00:11,274 [Thread-6       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local697544192_0001
   java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at mr.LogAnalysis$MyMapper.map(LogAnalysis.java:32)
	at mr.LogAnalysis$MyMapper.map(LogAnalysis.java:17)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[druid] 2018-11-01 17:00:11,644 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local697544192_0001 running in uber mode : false
   [druid] 2018-11-01 17:00:11,645 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-11-01 17:00:11,647 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local697544192_0001 failed with state FAILED due to: NA
   [druid] 2018-11-01 17:00:11,673 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2018-11-01 17:01:33,557 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:01:33,558 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:01:33,789 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 17:01:33,839 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 17:01:33,982 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 17:01:34,038 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 17:01:34,185 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1885099599_0001
   [druid] 2018-11-01 17:01:34,429 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 17:01:34,430 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1885099599_0001
   [druid] 2018-11-01 17:01:34,438 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 17:01:34,447 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:01:34,450 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 17:01:34,572 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 17:01:34,573 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1885099599_0001_m_000000_0
   [druid] 2018-11-01 17:01:34,601 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:01:34,608 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:01:34,654 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3bd07e9a
   [druid] 2018-11-01 17:01:34,663 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 17:01:34,710 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:01:34,710 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:01:34,710 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:01:34,710 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:01:34,710 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:01:34,714 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:01:34,722 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:01:34,722 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:01:34,722 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:01:34,722 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1478; bufvoid = 104857600
   [druid] 2018-11-01 17:01:34,722 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 17:01:34,738 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:01:34,747 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1885099599_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:01:34,759 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:01:34,760 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1885099599_0001_m_000000_0' done.
   [druid] 2018-11-01 17:01:34,760 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1885099599_0001_m_000000_0
   [druid] 2018-11-01 17:01:34,760 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1885099599_0001_m_000001_0
   [druid] 2018-11-01 17:01:34,761 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:01:34,761 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:01:34,796 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4c47ce3b
   [druid] 2018-11-01 17:01:34,800 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 17:01:34,830 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:01:34,830 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:01:34,830 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:01:34,831 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:01:34,831 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:01:34,831 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:01:34,833 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:01:34,833 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:01:34,834 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:01:34,834 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 496; bufvoid = 104857600
   [druid] 2018-11-01 17:01:34,834 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:01:34,954 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:01:34,962 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1885099599_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:01:34,974 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:01:34,974 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1885099599_0001_m_000001_0' done.
   [druid] 2018-11-01 17:01:34,974 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1885099599_0001_m_000001_0
   [druid] 2018-11-01 17:01:34,974 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1885099599_0001_m_000002_0
   [druid] 2018-11-01 17:01:34,977 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:01:34,977 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:01:35,019 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3a98880c
   [druid] 2018-11-01 17:01:35,021 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 17:01:35,062 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:01:35,062 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:01:35,062 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:01:35,062 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:01:35,063 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:01:35,063 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:01:35,066 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:01:35,066 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:01:35,066 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:01:35,066 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 457; bufvoid = 104857600
   [druid] 2018-11-01 17:01:35,066 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:01:35,102 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:01:35,118 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1885099599_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:01:35,120 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:01:35,120 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1885099599_0001_m_000002_0' done.
   [druid] 2018-11-01 17:01:35,120 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1885099599_0001_m_000002_0
   [druid] 2018-11-01 17:01:35,121 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 17:01:35,124 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 17:01:35,124 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1885099599_0001_r_000000_0
   [druid] 2018-11-01 17:01:35,135 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:01:35,135 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:01:35,173 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@643e2916
   [druid] 2018-11-01 17:01:35,176 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@693f4a6
   [druid] 2018-11-01 17:01:35,193 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 17:01:35,196 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1885099599_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 17:01:35,280 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1885099599_0001_m_000000_0 decomp: 1492 len: 1496 to MEMORY
   [druid] 2018-11-01 17:01:35,289 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1492 bytes from map-output for attempt_local1885099599_0001_m_000000_0
   [druid] 2018-11-01 17:01:35,291 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1492, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1492
   [druid] 2018-11-01 17:01:35,297 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1885099599_0001_m_000002_0 decomp: 463 len: 467 to MEMORY
   [druid] 2018-11-01 17:01:35,298 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 463 bytes from map-output for attempt_local1885099599_0001_m_000002_0
   [druid] 2018-11-01 17:01:35,298 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 463, inMemoryMapOutputs.size() -> 2, commitMemory -> 1492, usedMemory ->1955
   [druid] 2018-11-01 17:01:35,302 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1885099599_0001_m_000001_0 decomp: 502 len: 506 to MEMORY
   [druid] 2018-11-01 17:01:35,303 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 502 bytes from map-output for attempt_local1885099599_0001_m_000001_0
   [druid] 2018-11-01 17:01:35,303 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 502, inMemoryMapOutputs.size() -> 3, commitMemory -> 1955, usedMemory ->2457
   [druid] 2018-11-01 17:01:35,303 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 17:01:35,305 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:01:35,305 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 17:01:35,318 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 17:01:35,318 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 982 bytes
   [druid] 2018-11-01 17:01:35,320 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 2457 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 17:01:35,321 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 2457 bytes from disk
   [druid] 2018-11-01 17:01:35,322 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 17:01:35,322 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 17:01:35,323 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1992 bytes
   [druid] 2018-11-01 17:01:35,325 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:01:35,334 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 17:01:35,343 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1885099599_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:01:35,345 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:01:35,345 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1885099599_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 17:01:35,347 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1885099599_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local1885099599_0001_r_000000
   [druid] 2018-11-01 17:01:35,349 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 17:01:35,349 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1885099599_0001_r_000000_0' done.
   [druid] 2018-11-01 17:01:35,349 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1885099599_0001_r_000000_0
   [druid] 2018-11-01 17:01:35,350 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 17:01:35,439 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1885099599_0001 running in uber mode : false
   [druid] 2018-11-01 17:01:35,441 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 17:01:35,443 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1885099599_0001 completed successfully
   [druid] 2018-11-01 17:01:35,465 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=16742
		FILE: Number of bytes written=1161374
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=2431
		Map output materialized bytes=2469
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=2469
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1455947776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=2449
   [druid] 2018-11-01 17:03:36,546 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:03:36,548 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:03:36,907 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 17:03:36,987 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 17:03:37,203 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 17:03:37,274 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 17:03:37,474 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1140440744_0001
   [druid] 2018-11-01 17:03:38,014 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 17:03:38,015 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1140440744_0001
   [druid] 2018-11-01 17:03:38,027 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 17:03:38,035 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:03:38,038 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 17:03:38,153 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 17:03:38,155 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1140440744_0001_m_000000_0
   [druid] 2018-11-01 17:03:38,198 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:03:38,207 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:03:38,283 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@68416d3
   [druid] 2018-11-01 17:03:38,292 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 17:03:38,352 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:03:38,352 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:03:38,352 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:03:38,353 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:03:38,353 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:03:38,358 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:03:38,367 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:03:38,367 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:03:38,367 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:03:38,367 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 48; bufvoid = 104857600
   [druid] 2018-11-01 17:03:38,368 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 17:03:38,389 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:03:38,398 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1140440744_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:03:38,412 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:03:38,413 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1140440744_0001_m_000000_0' done.
   [druid] 2018-11-01 17:03:38,413 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1140440744_0001_m_000000_0
   [druid] 2018-11-01 17:03:38,413 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1140440744_0001_m_000001_0
   [druid] 2018-11-01 17:03:38,415 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:03:38,415 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:03:38,459 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6b130fdc
   [druid] 2018-11-01 17:03:38,462 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 17:03:38,498 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:03:38,498 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:03:38,498 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:03:38,498 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:03:38,499 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:03:38,499 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:03:38,502 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:03:38,503 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:03:38,503 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:03:38,503 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 16; bufvoid = 104857600
   [druid] 2018-11-01 17:03:38,503 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:03:38,523 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:03:38,529 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1140440744_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:03:38,532 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:03:38,532 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1140440744_0001_m_000001_0' done.
   [druid] 2018-11-01 17:03:38,532 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1140440744_0001_m_000001_0
   [druid] 2018-11-01 17:03:38,532 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1140440744_0001_m_000002_0
   [druid] 2018-11-01 17:03:38,534 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:03:38,534 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:03:38,599 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2840d860
   [druid] 2018-11-01 17:03:38,602 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 17:03:38,638 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:03:38,639 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:03:38,639 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:03:38,639 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:03:38,639 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:03:38,640 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:03:38,643 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:03:38,643 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:03:38,643 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:03:38,643 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 16; bufvoid = 104857600
   [druid] 2018-11-01 17:03:38,643 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:03:38,652 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:03:38,699 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1140440744_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:03:38,701 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:03:38,701 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1140440744_0001_m_000002_0' done.
   [druid] 2018-11-01 17:03:38,702 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1140440744_0001_m_000002_0
   [druid] 2018-11-01 17:03:38,703 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 17:03:38,707 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 17:03:38,708 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1140440744_0001_r_000000_0
   [druid] 2018-11-01 17:03:38,718 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:03:38,719 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:03:38,782 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@32bdc71b
   [druid] 2018-11-01 17:03:38,785 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1fc02402
   [druid] 2018-11-01 17:03:38,806 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 17:03:38,811 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1140440744_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 17:03:38,892 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1140440744_0001_m_000001_0 decomp: 20 len: 24 to MEMORY
   [druid] 2018-11-01 17:03:38,903 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 20 bytes from map-output for attempt_local1140440744_0001_m_000001_0
   [druid] 2018-11-01 17:03:38,906 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20
   [druid] 2018-11-01 17:03:38,913 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1140440744_0001_m_000000_0 decomp: 56 len: 60 to MEMORY
   [druid] 2018-11-01 17:03:38,914 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 56 bytes from map-output for attempt_local1140440744_0001_m_000000_0
   [druid] 2018-11-01 17:03:38,914 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 56, inMemoryMapOutputs.size() -> 2, commitMemory -> 20, usedMemory ->76
   [druid] 2018-11-01 17:03:38,920 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1140440744_0001_m_000002_0 decomp: 20 len: 24 to MEMORY
   [druid] 2018-11-01 17:03:38,924 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 20 bytes from map-output for attempt_local1140440744_0001_m_000002_0
   [druid] 2018-11-01 17:03:38,924 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 3, commitMemory -> 76, usedMemory ->96
   [druid] 2018-11-01 17:03:38,924 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 17:03:38,926 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:03:38,926 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 17:03:38,946 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 17:03:38,947 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 42 bytes
   [druid] 2018-11-01 17:03:38,957 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 96 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 17:03:38,959 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 96 bytes from disk
   [druid] 2018-11-01 17:03:38,959 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 17:03:38,959 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 17:03:38,961 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 74 bytes
   [druid] 2018-11-01 17:03:38,962 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:03:38,979 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 17:03:38,993 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1140440744_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:03:38,996 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:03:38,996 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1140440744_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 17:03:39,012 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1140440744_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local1140440744_0001_r_000000
   [druid] 2018-11-01 17:03:39,018 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1140440744_0001 running in uber mode : false
   [druid] 2018-11-01 17:03:39,020 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-11-01 17:03:39,033 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 17:03:39,034 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1140440744_0001_r_000000_0' done.
   [druid] 2018-11-01 17:03:39,034 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1140440744_0001_r_000000_0
   [druid] 2018-11-01 17:03:39,034 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 17:03:40,025 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 17:03:40,026 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1140440744_0001 completed successfully
   [druid] 2018-11-01 17:03:40,048 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=12020
		FILE: Number of bytes written=1148580
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=80
		Map output materialized bytes=108
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=108
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1590165504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=92
   [druid] 2018-11-01 17:04:38,571 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:04:38,573 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:04:38,806 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 17:04:38,877 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 17:04:39,040 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 17:04:39,091 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 17:04:39,247 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local845581248_0001
   [druid] 2018-11-01 17:04:39,477 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 17:04:39,478 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local845581248_0001
   [druid] 2018-11-01 17:04:39,486 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 17:04:39,493 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:04:39,496 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 17:04:39,631 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 17:04:39,631 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local845581248_0001_m_000000_0
   [druid] 2018-11-01 17:04:39,660 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:04:39,674 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:04:39,726 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3ebb4c16
   [druid] 2018-11-01 17:04:39,735 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 17:04:39,787 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:04:39,788 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:04:39,788 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:04:39,788 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:04:39,788 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:04:39,792 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:04:39,801 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:04:39,801 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:04:39,801 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:04:39,801 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 48; bufvoid = 104857600
   [druid] 2018-11-01 17:04:39,802 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 17:04:39,815 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:04:39,822 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local845581248_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:04:39,832 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:04:39,832 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local845581248_0001_m_000000_0' done.
   [druid] 2018-11-01 17:04:39,832 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local845581248_0001_m_000000_0
   [druid] 2018-11-01 17:04:39,832 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local845581248_0001_m_000001_0
   [druid] 2018-11-01 17:04:39,833 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:04:39,834 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:04:39,876 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@37317a1d
   [druid] 2018-11-01 17:04:39,879 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 17:04:39,914 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:04:39,914 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:04:39,914 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:04:39,914 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:04:39,915 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:04:39,915 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:04:39,918 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:04:39,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:04:39,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:04:39,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 16; bufvoid = 104857600
   [druid] 2018-11-01 17:04:39,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:04:39,925 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:04:39,941 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local845581248_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:04:39,948 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:04:39,948 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local845581248_0001_m_000001_0' done.
   [druid] 2018-11-01 17:04:39,948 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local845581248_0001_m_000001_0
   [druid] 2018-11-01 17:04:39,948 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local845581248_0001_m_000002_0
   [druid] 2018-11-01 17:04:39,950 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:04:39,950 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:04:40,008 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6cba07af
   [druid] 2018-11-01 17:04:40,012 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 17:04:40,052 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:04:40,052 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:04:40,052 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:04:40,052 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:04:40,052 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:04:40,053 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:04:40,055 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:04:40,055 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:04:40,056 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:04:40,056 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 16; bufvoid = 104857600
   [druid] 2018-11-01 17:04:40,056 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:04:40,066 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:04:40,071 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local845581248_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:04:40,075 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:04:40,076 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local845581248_0001_m_000002_0' done.
   [druid] 2018-11-01 17:04:40,076 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local845581248_0001_m_000002_0
   [druid] 2018-11-01 17:04:40,076 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 17:04:40,080 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 17:04:40,080 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local845581248_0001_r_000000_0
   [druid] 2018-11-01 17:04:40,089 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:04:40,090 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:04:40,130 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@18bce3c
   [druid] 2018-11-01 17:04:40,133 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@791b2213
   [druid] 2018-11-01 17:04:40,147 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 17:04:40,150 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local845581248_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 17:04:40,211 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local845581248_0001_m_000002_0 decomp: 20 len: 24 to MEMORY
   [druid] 2018-11-01 17:04:40,225 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 20 bytes from map-output for attempt_local845581248_0001_m_000002_0
   [druid] 2018-11-01 17:04:40,228 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20
   [druid] 2018-11-01 17:04:40,236 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local845581248_0001_m_000000_0 decomp: 56 len: 60 to MEMORY
   [druid] 2018-11-01 17:04:40,244 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 56 bytes from map-output for attempt_local845581248_0001_m_000000_0
   [druid] 2018-11-01 17:04:40,244 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 56, inMemoryMapOutputs.size() -> 2, commitMemory -> 20, usedMemory ->76
   [druid] 2018-11-01 17:04:40,255 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local845581248_0001_m_000001_0 decomp: 20 len: 24 to MEMORY
   [druid] 2018-11-01 17:04:40,257 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 20 bytes from map-output for attempt_local845581248_0001_m_000001_0
   [druid] 2018-11-01 17:04:40,257 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 3, commitMemory -> 76, usedMemory ->96
   [druid] 2018-11-01 17:04:40,259 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 17:04:40,265 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:04:40,265 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 17:04:40,302 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 17:04:40,302 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 42 bytes
   [druid] 2018-11-01 17:04:40,307 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 96 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 17:04:40,308 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 96 bytes from disk
   [druid] 2018-11-01 17:04:40,309 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 17:04:40,309 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 17:04:40,311 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 74 bytes
   [druid] 2018-11-01 17:04:40,311 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:04:40,319 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 17:04:40,327 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local845581248_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:04:40,328 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:04:40,329 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local845581248_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 17:04:40,331 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local845581248_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local845581248_0001_r_000000
   [druid] 2018-11-01 17:04:40,336 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 17:04:40,337 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local845581248_0001_r_000000_0' done.
   [druid] 2018-11-01 17:04:40,337 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local845581248_0001_r_000000_0
   [druid] 2018-11-01 17:04:40,337 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 17:04:40,481 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local845581248_0001 running in uber mode : false
   [druid] 2018-11-01 17:04:40,484 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 17:04:40,485 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local845581248_0001 completed successfully
   [druid] 2018-11-01 17:04:40,506 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=12020
		FILE: Number of bytes written=1137796
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=80
		Map output materialized bytes=108
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=108
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1455947776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=92
   [druid] 2018-11-01 17:05:19,571 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:05:19,572 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:05:19,861 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 17:05:19,918 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 17:05:20,095 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 17:05:20,150 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 17:05:20,326 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1755918940_0001
   [druid] 2018-11-01 17:05:20,583 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 17:05:20,584 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1755918940_0001
   [druid] 2018-11-01 17:05:20,586 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 17:05:20,594 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:05:20,596 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 17:05:20,686 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 17:05:20,687 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1755918940_0001_m_000000_0
   [druid] 2018-11-01 17:05:20,721 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:05:20,729 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:05:20,774 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4f374217
   [druid] 2018-11-01 17:05:20,781 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 17:05:20,833 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:05:20,833 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:05:20,833 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:05:20,833 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:05:20,833 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:05:20,836 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:05:20,843 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:05:20,863 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1755918940_0001_m_000001_0
   [druid] 2018-11-01 17:05:20,864 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:05:20,865 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:05:20,908 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@122b1006
   [druid] 2018-11-01 17:05:20,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 17:05:20,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:05:20,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:05:20,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:05:20,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:05:20,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:05:20,943 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:05:20,945 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:05:20,957 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1755918940_0001_m_000002_0
   [druid] 2018-11-01 17:05:20,958 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:05:20,959 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:05:21,005 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2c2ab697
   [druid] 2018-11-01 17:05:21,008 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 17:05:21,041 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:05:21,041 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:05:21,041 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:05:21,041 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:05:21,041 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:05:21,042 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:05:21,043 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:05:21,066 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 17:05:21,072 [Thread-6       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1755918940_0001
   java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at mr.LogAnalysis$MyMapper.map(LogAnalysis.java:32)
	at mr.LogAnalysis$MyMapper.map(LogAnalysis.java:17)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[druid] 2018-11-01 17:05:21,586 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1755918940_0001 running in uber mode : false
   [druid] 2018-11-01 17:05:21,587 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-11-01 17:05:21,589 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1755918940_0001 failed with state FAILED due to: NA
   [druid] 2018-11-01 17:05:21,594 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2018-11-01 17:05:45,844 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:05:45,847 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:05:46,164 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 17:05:46,230 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 17:05:46,398 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 17:05:46,448 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 17:05:46,619 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1781476112_0001
   [druid] 2018-11-01 17:05:46,937 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 17:05:46,937 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1781476112_0001
   [druid] 2018-11-01 17:05:46,942 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 17:05:46,951 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:05:46,954 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 17:05:47,071 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 17:05:47,071 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1781476112_0001_m_000000_0
   [druid] 2018-11-01 17:05:47,099 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:05:47,104 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:05:47,139 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2b43fcb5
   [druid] 2018-11-01 17:05:47,147 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 17:05:47,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:05:47,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:05:47,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:05:47,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:05:47,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:05:47,201 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:05:47,210 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:05:47,210 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:05:47,210 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:05:47,210 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 45; bufvoid = 104857600
   [druid] 2018-11-01 17:05:47,210 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 17:05:47,230 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:05:47,238 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1781476112_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:05:47,249 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:05:47,250 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1781476112_0001_m_000000_0' done.
   [druid] 2018-11-01 17:05:47,250 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1781476112_0001_m_000000_0
   [druid] 2018-11-01 17:05:47,250 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1781476112_0001_m_000001_0
   [druid] 2018-11-01 17:05:47,252 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:05:47,252 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:05:47,288 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@69636bb8
   [druid] 2018-11-01 17:05:47,291 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 17:05:47,320 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:05:47,321 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:05:47,321 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:05:47,321 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:05:47,321 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:05:47,321 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:05:47,323 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:05:47,323 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:05:47,323 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:05:47,323 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 15; bufvoid = 104857600
   [druid] 2018-11-01 17:05:47,323 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:05:47,331 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:05:47,338 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1781476112_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:05:47,340 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:05:47,340 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1781476112_0001_m_000001_0' done.
   [druid] 2018-11-01 17:05:47,340 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1781476112_0001_m_000001_0
   [druid] 2018-11-01 17:05:47,341 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1781476112_0001_m_000002_0
   [druid] 2018-11-01 17:05:47,341 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:05:47,342 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:05:47,403 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@745c7816
   [druid] 2018-11-01 17:05:47,406 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 17:05:47,441 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:05:47,441 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:05:47,441 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:05:47,441 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:05:47,442 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:05:47,442 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:05:47,445 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:05:47,445 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:05:47,446 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:05:47,446 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 15; bufvoid = 104857600
   [druid] 2018-11-01 17:05:47,446 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:05:47,459 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:05:47,465 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1781476112_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:05:47,474 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:05:47,475 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1781476112_0001_m_000002_0' done.
   [druid] 2018-11-01 17:05:47,475 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1781476112_0001_m_000002_0
   [druid] 2018-11-01 17:05:47,475 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 17:05:47,478 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 17:05:47,479 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1781476112_0001_r_000000_0
   [druid] 2018-11-01 17:05:47,486 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:05:47,486 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:05:47,526 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6287dd67
   [druid] 2018-11-01 17:05:47,529 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7892aa4d
   [druid] 2018-11-01 17:05:47,540 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 17:05:47,542 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1781476112_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 17:05:47,601 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1781476112_0001_m_000001_0 decomp: 19 len: 23 to MEMORY
   [druid] 2018-11-01 17:05:47,614 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 19 bytes from map-output for attempt_local1781476112_0001_m_000001_0
   [druid] 2018-11-01 17:05:47,617 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 19, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->19
   [druid] 2018-11-01 17:05:47,623 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1781476112_0001_m_000002_0 decomp: 19 len: 23 to MEMORY
   [druid] 2018-11-01 17:05:47,624 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 19 bytes from map-output for attempt_local1781476112_0001_m_000002_0
   [druid] 2018-11-01 17:05:47,625 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 19, inMemoryMapOutputs.size() -> 2, commitMemory -> 19, usedMemory ->38
   [druid] 2018-11-01 17:05:47,630 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1781476112_0001_m_000000_0 decomp: 53 len: 57 to MEMORY
   [druid] 2018-11-01 17:05:47,631 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 53 bytes from map-output for attempt_local1781476112_0001_m_000000_0
   [druid] 2018-11-01 17:05:47,631 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 53, inMemoryMapOutputs.size() -> 3, commitMemory -> 38, usedMemory ->91
   [druid] 2018-11-01 17:05:47,632 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 17:05:47,633 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:05:47,633 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 17:05:47,667 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 17:05:47,667 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 40 bytes
   [druid] 2018-11-01 17:05:47,671 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 91 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 17:05:47,672 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 91 bytes from disk
   [druid] 2018-11-01 17:05:47,673 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 17:05:47,673 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 17:05:47,675 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 70 bytes
   [druid] 2018-11-01 17:05:47,676 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:05:47,717 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 17:05:47,730 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1781476112_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:05:47,731 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:05:47,731 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1781476112_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 17:05:47,733 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1781476112_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local1781476112_0001_r_000000
   [druid] 2018-11-01 17:05:47,734 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 17:05:47,734 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1781476112_0001_r_000000_0' done.
   [druid] 2018-11-01 17:05:47,734 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1781476112_0001_r_000000_0
   [druid] 2018-11-01 17:05:47,734 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 17:05:47,940 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1781476112_0001 running in uber mode : false
   [druid] 2018-11-01 17:05:47,941 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 17:05:47,942 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1781476112_0001 completed successfully
   [druid] 2018-11-01 17:05:47,954 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=12010
		FILE: Number of bytes written=1143657
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=75
		Map output materialized bytes=103
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=103
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1455947776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=87
   [druid] 2018-11-01 17:06:45,978 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:06:45,980 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:06:46,225 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 17:06:46,274 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 17:06:46,414 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 17:06:46,461 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 17:06:46,604 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local570555562_0001
   [druid] 2018-11-01 17:06:46,819 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 17:06:46,821 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local570555562_0001
   [druid] 2018-11-01 17:06:46,829 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 17:06:46,835 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:06:46,839 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 17:06:46,933 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 17:06:46,934 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local570555562_0001_m_000000_0
   [druid] 2018-11-01 17:06:46,973 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:06:46,980 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:06:47,027 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@468f20d0
   [druid] 2018-11-01 17:06:47,035 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 17:06:47,088 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:06:47,088 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:06:47,088 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:06:47,088 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:06:47,088 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:06:47,093 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:06:47,101 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:06:47,101 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:06:47,101 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:06:47,101 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 42; bufvoid = 104857600
   [druid] 2018-11-01 17:06:47,101 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 17:06:47,122 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:06:47,128 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local570555562_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:06:47,139 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:06:47,139 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local570555562_0001_m_000000_0' done.
   [druid] 2018-11-01 17:06:47,139 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local570555562_0001_m_000000_0
   [druid] 2018-11-01 17:06:47,140 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local570555562_0001_m_000001_0
   [druid] 2018-11-01 17:06:47,141 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:06:47,142 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:06:47,178 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@629079a2
   [druid] 2018-11-01 17:06:47,181 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 17:06:47,212 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:06:47,212 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:06:47,212 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:06:47,212 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:06:47,212 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:06:47,213 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:06:47,215 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:06:47,215 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:06:47,215 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:06:47,215 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 14; bufvoid = 104857600
   [druid] 2018-11-01 17:06:47,215 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:06:47,222 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:06:47,237 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local570555562_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:06:47,243 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:06:47,243 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local570555562_0001_m_000001_0' done.
   [druid] 2018-11-01 17:06:47,243 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local570555562_0001_m_000001_0
   [druid] 2018-11-01 17:06:47,243 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local570555562_0001_m_000002_0
   [druid] 2018-11-01 17:06:47,244 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:06:47,245 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:06:47,296 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1b85c5b8
   [druid] 2018-11-01 17:06:47,299 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 17:06:47,337 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:06:47,337 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:06:47,338 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:06:47,338 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:06:47,338 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:06:47,338 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:06:47,341 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:06:47,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:06:47,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:06:47,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 14; bufvoid = 104857600
   [druid] 2018-11-01 17:06:47,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:06:47,366 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:06:47,371 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local570555562_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:06:47,374 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:06:47,374 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local570555562_0001_m_000002_0' done.
   [druid] 2018-11-01 17:06:47,374 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local570555562_0001_m_000002_0
   [druid] 2018-11-01 17:06:47,374 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 17:06:47,377 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 17:06:47,377 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local570555562_0001_r_000000_0
   [druid] 2018-11-01 17:06:47,386 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:06:47,387 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:06:47,431 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@58c7c9d9
   [druid] 2018-11-01 17:06:47,433 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@197e71f6
   [druid] 2018-11-01 17:06:47,446 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 17:06:47,448 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local570555562_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 17:06:47,509 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local570555562_0001_m_000001_0 decomp: 18 len: 22 to MEMORY
   [druid] 2018-11-01 17:06:47,520 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 18 bytes from map-output for attempt_local570555562_0001_m_000001_0
   [druid] 2018-11-01 17:06:47,523 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 18, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->18
   [druid] 2018-11-01 17:06:47,529 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local570555562_0001_m_000002_0 decomp: 18 len: 22 to MEMORY
   [druid] 2018-11-01 17:06:47,531 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 18 bytes from map-output for attempt_local570555562_0001_m_000002_0
   [druid] 2018-11-01 17:06:47,531 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 18, inMemoryMapOutputs.size() -> 2, commitMemory -> 18, usedMemory ->36
   [druid] 2018-11-01 17:06:47,537 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local570555562_0001_m_000000_0 decomp: 50 len: 54 to MEMORY
   [druid] 2018-11-01 17:06:47,538 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 50 bytes from map-output for attempt_local570555562_0001_m_000000_0
   [druid] 2018-11-01 17:06:47,538 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 3, commitMemory -> 36, usedMemory ->86
   [druid] 2018-11-01 17:06:47,540 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 17:06:47,541 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:06:47,541 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 17:06:47,571 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 17:06:47,571 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 38 bytes
   [druid] 2018-11-01 17:06:47,573 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 86 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 17:06:47,574 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 86 bytes from disk
   [druid] 2018-11-01 17:06:47,575 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 17:06:47,575 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 17:06:47,577 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 66 bytes
   [druid] 2018-11-01 17:06:47,577 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:06:47,583 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 17:06:47,595 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local570555562_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:06:47,597 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:06:47,597 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local570555562_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 17:06:47,601 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local570555562_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local570555562_0001_r_000000
   [druid] 2018-11-01 17:06:47,604 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 17:06:47,604 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local570555562_0001_r_000000_0' done.
   [druid] 2018-11-01 17:06:47,605 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local570555562_0001_r_000000_0
   [druid] 2018-11-01 17:06:47,605 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 17:06:47,824 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local570555562_0001 running in uber mode : false
   [druid] 2018-11-01 17:06:47,825 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 17:06:47,826 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local570555562_0001 completed successfully
   [druid] 2018-11-01 17:06:47,837 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=12000
		FILE: Number of bytes written=1137742
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=70
		Map output materialized bytes=98
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=98
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1571291136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=82
   [druid] 2018-11-01 17:35:41,882 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:35:41,883 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:35:42,158 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 17:35:42,211 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 17:35:42,360 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 17:35:42,419 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 17:35:42,577 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local327096480_0001
   [druid] 2018-11-01 17:35:42,847 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 17:35:42,848 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local327096480_0001
   [druid] 2018-11-01 17:35:42,859 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 17:35:42,866 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:35:42,883 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 17:35:42,980 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 17:35:42,982 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local327096480_0001_m_000000_0
   [druid] 2018-11-01 17:35:43,021 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:35:43,031 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:35:43,077 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@30af75d9
   [druid] 2018-11-01 17:35:43,086 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 17:35:43,177 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:35:43,177 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:35:43,177 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:35:43,177 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:35:43,177 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:35:43,182 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:35:43,191 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:35:43,192 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:35:43,192 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:35:43,192 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 45; bufvoid = 104857600
   [druid] 2018-11-01 17:35:43,192 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 17:35:43,203 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:35:43,210 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local327096480_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:35:43,219 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:35:43,220 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local327096480_0001_m_000000_0' done.
   [druid] 2018-11-01 17:35:43,220 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local327096480_0001_m_000000_0
   [druid] 2018-11-01 17:35:43,220 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local327096480_0001_m_000001_0
   [druid] 2018-11-01 17:35:43,221 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:35:43,222 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:35:43,255 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@c5ae147
   [druid] 2018-11-01 17:35:43,257 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 17:35:43,325 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:35:43,325 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:35:43,325 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:35:43,325 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:35:43,325 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:35:43,327 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:35:43,329 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:35:43,330 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:35:43,330 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:35:43,330 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 15; bufvoid = 104857600
   [druid] 2018-11-01 17:35:43,330 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:35:43,336 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:35:43,343 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local327096480_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:35:43,350 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:35:43,350 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local327096480_0001_m_000001_0' done.
   [druid] 2018-11-01 17:35:43,350 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local327096480_0001_m_000001_0
   [druid] 2018-11-01 17:35:43,350 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local327096480_0001_m_000002_0
   [druid] 2018-11-01 17:35:43,356 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:35:43,356 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:35:43,402 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@15a86b24
   [druid] 2018-11-01 17:35:43,406 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 17:35:43,460 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:35:43,460 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:35:43,460 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:35:43,460 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:35:43,460 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:35:43,461 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:35:43,463 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:35:43,463 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:35:43,463 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:35:43,463 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 15; bufvoid = 104857600
   [druid] 2018-11-01 17:35:43,463 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:35:43,470 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:35:43,475 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local327096480_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:35:43,477 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:35:43,478 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local327096480_0001_m_000002_0' done.
   [druid] 2018-11-01 17:35:43,478 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local327096480_0001_m_000002_0
   [druid] 2018-11-01 17:35:43,478 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 17:35:43,480 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 17:35:43,481 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local327096480_0001_r_000000_0
   [druid] 2018-11-01 17:35:43,488 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:35:43,489 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:35:43,524 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@31307254
   [druid] 2018-11-01 17:35:43,527 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3247879b
   [druid] 2018-11-01 17:35:43,543 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 17:35:43,547 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local327096480_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 17:35:43,659 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local327096480_0001_m_000002_0 decomp: 19 len: 23 to MEMORY
   [druid] 2018-11-01 17:35:43,698 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 19 bytes from map-output for attempt_local327096480_0001_m_000002_0
   [druid] 2018-11-01 17:35:43,700 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 19, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->19
   [druid] 2018-11-01 17:35:43,708 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local327096480_0001_m_000001_0 decomp: 19 len: 23 to MEMORY
   [druid] 2018-11-01 17:35:43,710 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 19 bytes from map-output for attempt_local327096480_0001_m_000001_0
   [druid] 2018-11-01 17:35:43,710 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 19, inMemoryMapOutputs.size() -> 2, commitMemory -> 19, usedMemory ->38
   [druid] 2018-11-01 17:35:43,716 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local327096480_0001_m_000000_0 decomp: 53 len: 57 to MEMORY
   [druid] 2018-11-01 17:35:43,717 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 53 bytes from map-output for attempt_local327096480_0001_m_000000_0
   [druid] 2018-11-01 17:35:43,718 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 53, inMemoryMapOutputs.size() -> 3, commitMemory -> 38, usedMemory ->91
   [druid] 2018-11-01 17:35:43,718 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 17:35:43,720 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:35:43,721 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 17:35:43,852 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local327096480_0001 running in uber mode : false
   [druid] 2018-11-01 17:35:43,853 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-11-01 17:35:45,050 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 17:35:45,050 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 85 bytes
   [druid] 2018-11-01 17:35:45,055 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 91 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 17:35:45,056 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 91 bytes from disk
   [druid] 2018-11-01 17:35:45,057 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 17:35:45,057 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 17:35:45,058 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 85 bytes
   [druid] 2018-11-01 17:35:45,058 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:35:45,322 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 17:35:45,328 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local327096480_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:35:45,330 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:35:45,330 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local327096480_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 17:35:45,334 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local327096480_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local327096480_0001_r_000000
   [druid] 2018-11-01 17:35:45,337 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 17:35:45,337 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local327096480_0001_r_000000_0' done.
   [druid] 2018-11-01 17:35:45,337 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local327096480_0001_r_000000_0
   [druid] 2018-11-01 17:35:45,341 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 17:35:45,854 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 17:35:45,854 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local327096480_0001 completed successfully
   [druid] 2018-11-01 17:35:45,869 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=12010
		FILE: Number of bytes written=1137769
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=75
		Map output materialized bytes=103
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=103
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1455947776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=87
   [druid] 2018-11-01 17:36:37,628 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:36:37,631 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:36:50,718 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:36:50,720 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:36:51,003 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 17:36:51,054 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 17:36:51,269 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 17:36:51,334 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 17:36:51,493 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local926357101_0001
   [druid] 2018-11-01 17:36:51,858 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 17:36:51,859 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local926357101_0001
   [druid] 2018-11-01 17:36:51,864 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 17:36:51,872 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:36:51,875 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 17:36:51,960 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 17:36:51,968 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local926357101_0001_m_000000_0
   [druid] 2018-11-01 17:36:51,999 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:36:52,009 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:36:52,047 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@56e1cde4
   [druid] 2018-11-01 17:36:52,053 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 17:36:52,097 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:36:52,097 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:36:52,097 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:36:52,097 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:36:52,097 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:36:52,100 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:36:52,113 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:36:52,113 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:36:52,113 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:36:52,113 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 84; bufvoid = 104857600
   [druid] 2018-11-01 17:36:52,113 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 17:36:52,127 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:36:52,135 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local926357101_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:36:52,167 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:36:52,167 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local926357101_0001_m_000000_0' done.
   [druid] 2018-11-01 17:36:52,167 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local926357101_0001_m_000000_0
   [druid] 2018-11-01 17:36:52,167 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local926357101_0001_m_000001_0
   [druid] 2018-11-01 17:36:52,169 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:36:52,170 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:36:52,211 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@51f2a87b
   [druid] 2018-11-01 17:36:52,214 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 17:36:52,246 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:36:52,246 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:36:52,246 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:36:52,246 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:36:52,246 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:36:52,247 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:36:52,249 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:36:52,249 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:36:52,249 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:36:52,249 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 28; bufvoid = 104857600
   [druid] 2018-11-01 17:36:52,249 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:36:52,256 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:36:52,260 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local926357101_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:36:52,263 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:36:52,263 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local926357101_0001_m_000001_0' done.
   [druid] 2018-11-01 17:36:52,263 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local926357101_0001_m_000001_0
   [druid] 2018-11-01 17:36:52,264 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local926357101_0001_m_000002_0
   [druid] 2018-11-01 17:36:52,265 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:36:52,266 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:36:52,314 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1d4dc799
   [druid] 2018-11-01 17:36:52,316 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 17:36:52,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:36:52,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:36:52,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:36:52,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:36:52,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:36:52,366 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:36:52,369 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:36:52,369 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:36:52,369 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:36:52,369 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 28; bufvoid = 104857600
   [druid] 2018-11-01 17:36:52,369 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:36:52,379 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:36:52,422 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local926357101_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:36:52,425 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:36:52,425 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local926357101_0001_m_000002_0' done.
   [druid] 2018-11-01 17:36:52,425 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local926357101_0001_m_000002_0
   [druid] 2018-11-01 17:36:52,425 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 17:36:52,427 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 17:36:52,428 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local926357101_0001_r_000000_0
   [druid] 2018-11-01 17:36:52,435 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:36:52,435 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:36:52,480 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@d8bb68a
   [druid] 2018-11-01 17:36:52,483 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@446832b0
   [druid] 2018-11-01 17:36:52,495 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 17:36:52,498 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local926357101_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 17:36:52,538 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local926357101_0001_m_000002_0 decomp: 32 len: 36 to MEMORY
   [druid] 2018-11-01 17:36:52,544 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 32 bytes from map-output for attempt_local926357101_0001_m_000002_0
   [druid] 2018-11-01 17:36:52,546 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 32, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->32
   [druid] 2018-11-01 17:36:52,550 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local926357101_0001_m_000001_0 decomp: 32 len: 36 to MEMORY
   [druid] 2018-11-01 17:36:52,551 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 32 bytes from map-output for attempt_local926357101_0001_m_000001_0
   [druid] 2018-11-01 17:36:52,551 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 32, inMemoryMapOutputs.size() -> 2, commitMemory -> 32, usedMemory ->64
   [druid] 2018-11-01 17:36:52,554 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local926357101_0001_m_000000_0 decomp: 92 len: 96 to MEMORY
   [druid] 2018-11-01 17:36:52,555 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 92 bytes from map-output for attempt_local926357101_0001_m_000000_0
   [druid] 2018-11-01 17:36:52,555 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 92, inMemoryMapOutputs.size() -> 3, commitMemory -> 64, usedMemory ->156
   [druid] 2018-11-01 17:36:52,562 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 17:36:52,688 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:36:52,688 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 17:36:52,708 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 17:36:52,709 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 150 bytes
   [druid] 2018-11-01 17:36:52,711 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 156 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 17:36:52,712 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 156 bytes from disk
   [druid] 2018-11-01 17:36:52,713 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 17:36:52,713 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 17:36:52,715 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 150 bytes
   [druid] 2018-11-01 17:36:52,715 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:36:52,732 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 17:36:52,749 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local926357101_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:36:52,752 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:36:52,752 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local926357101_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 17:36:52,758 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local926357101_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local926357101_0001_r_000000
   [druid] 2018-11-01 17:36:52,759 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 17:36:52,759 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local926357101_0001_r_000000_0' done.
   [druid] 2018-11-01 17:36:52,759 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local926357101_0001_r_000000_0
   [druid] 2018-11-01 17:36:52,760 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 17:36:52,878 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local926357101_0001 running in uber mode : false
   [druid] 2018-11-01 17:36:52,880 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 17:36:52,881 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local926357101_0001 completed successfully
   [druid] 2018-11-01 17:36:52,922 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=12140
		FILE: Number of bytes written=1138120
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=140
		Map output materialized bytes=168
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=168
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1590165504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=152
   [druid] 2018-11-01 17:37:33,217 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:37:33,219 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:37:33,549 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 17:37:33,621 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 17:37:33,809 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 17:37:33,854 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 17:37:34,129 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1373830367_0001
   [druid] 2018-11-01 17:37:34,418 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 17:37:34,419 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1373830367_0001
   [druid] 2018-11-01 17:37:34,459 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 17:37:34,466 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:37:34,469 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 17:37:34,562 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 17:37:34,568 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1373830367_0001_m_000000_0
   [druid] 2018-11-01 17:37:34,602 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:37:34,609 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:37:34,677 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6afcfcd7
   [druid] 2018-11-01 17:37:34,684 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 17:37:34,727 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:37:34,728 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:37:34,728 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:37:34,728 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:37:34,728 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:37:34,735 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:37:34,743 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:37:34,743 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:37:34,743 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:37:34,743 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 87; bufvoid = 104857600
   [druid] 2018-11-01 17:37:34,743 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 17:37:34,756 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:37:34,762 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1373830367_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:37:34,773 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:37:34,773 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1373830367_0001_m_000000_0' done.
   [druid] 2018-11-01 17:37:34,773 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1373830367_0001_m_000000_0
   [druid] 2018-11-01 17:37:34,773 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1373830367_0001_m_000001_0
   [druid] 2018-11-01 17:37:34,775 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:37:34,775 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:37:34,808 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6a814c4
   [druid] 2018-11-01 17:37:34,811 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 17:37:34,842 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:37:34,842 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:37:34,842 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:37:34,842 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:37:34,842 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:37:34,842 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:37:34,845 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:37:34,845 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:37:34,845 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:37:34,845 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 29; bufvoid = 104857600
   [druid] 2018-11-01 17:37:34,845 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:37:34,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:37:34,866 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1373830367_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:37:34,872 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:37:34,872 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1373830367_0001_m_000001_0' done.
   [druid] 2018-11-01 17:37:34,872 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1373830367_0001_m_000001_0
   [druid] 2018-11-01 17:37:34,872 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1373830367_0001_m_000002_0
   [druid] 2018-11-01 17:37:34,873 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:37:34,874 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:37:34,915 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3159c91f
   [druid] 2018-11-01 17:37:34,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 17:37:34,954 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:37:34,954 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:37:34,954 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:37:34,954 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:37:34,954 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:37:34,955 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:37:34,957 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:37:34,957 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:37:34,957 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:37:34,958 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 29; bufvoid = 104857600
   [druid] 2018-11-01 17:37:34,958 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:37:34,978 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:37:34,987 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1373830367_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:37:34,989 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:37:34,990 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1373830367_0001_m_000002_0' done.
   [druid] 2018-11-01 17:37:34,990 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1373830367_0001_m_000002_0
   [druid] 2018-11-01 17:37:34,991 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 17:37:34,994 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 17:37:34,994 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1373830367_0001_r_000000_0
   [druid] 2018-11-01 17:37:35,007 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:37:35,007 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:37:35,050 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@624962e7
   [druid] 2018-11-01 17:37:35,052 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@258039ee
   [druid] 2018-11-01 17:37:35,064 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 17:37:35,066 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1373830367_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 17:37:35,133 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1373830367_0001_m_000000_0 decomp: 95 len: 99 to MEMORY
   [druid] 2018-11-01 17:37:35,148 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 95 bytes from map-output for attempt_local1373830367_0001_m_000000_0
   [druid] 2018-11-01 17:37:35,151 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 95, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->95
   [druid] 2018-11-01 17:37:35,158 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1373830367_0001_m_000001_0 decomp: 33 len: 37 to MEMORY
   [druid] 2018-11-01 17:37:35,161 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 33 bytes from map-output for attempt_local1373830367_0001_m_000001_0
   [druid] 2018-11-01 17:37:35,161 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 2, commitMemory -> 95, usedMemory ->128
   [druid] 2018-11-01 17:37:35,166 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1373830367_0001_m_000002_0 decomp: 33 len: 37 to MEMORY
   [druid] 2018-11-01 17:37:35,170 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 33 bytes from map-output for attempt_local1373830367_0001_m_000002_0
   [druid] 2018-11-01 17:37:35,171 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 3, commitMemory -> 128, usedMemory ->161
   [druid] 2018-11-01 17:37:35,172 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 17:37:35,174 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:37:35,174 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 17:37:35,197 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 17:37:35,198 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 155 bytes
   [druid] 2018-11-01 17:37:35,203 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 161 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 17:37:35,204 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 161 bytes from disk
   [druid] 2018-11-01 17:37:35,205 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 17:37:35,205 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 17:37:35,207 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 155 bytes
   [druid] 2018-11-01 17:37:35,208 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:37:35,216 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 17:37:35,233 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1373830367_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:37:35,234 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:37:35,234 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1373830367_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 17:37:35,237 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1373830367_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local1373830367_0001_r_000000
   [druid] 2018-11-01 17:37:35,242 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 17:37:35,242 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1373830367_0001_r_000000_0' done.
   [druid] 2018-11-01 17:37:35,243 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1373830367_0001_r_000000_0
   [druid] 2018-11-01 17:37:35,243 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 17:37:35,422 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1373830367_0001 running in uber mode : false
   [druid] 2018-11-01 17:37:35,423 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 17:37:35,424 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1373830367_0001 completed successfully
   [druid] 2018-11-01 17:37:35,450 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=12150
		FILE: Number of bytes written=1144035
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=145
		Map output materialized bytes=173
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=173
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1590165504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=157
   [druid] 2018-11-01 17:47:54,975 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 17:47:54,977 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 17:47:55,299 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 17:47:55,353 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 17:47:55,542 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 17:47:55,594 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 17:47:55,774 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local2065193994_0001
   [druid] 2018-11-01 17:47:56,121 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 17:47:56,123 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local2065193994_0001
   [druid] 2018-11-01 17:47:56,125 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 17:47:56,132 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:47:56,135 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 17:47:56,207 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 17:47:56,207 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2065193994_0001_m_000000_0
   [druid] 2018-11-01 17:47:56,239 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:47:56,246 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:47:56,284 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6708edd0
   [druid] 2018-11-01 17:47:56,290 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 17:47:56,340 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:47:56,340 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:47:56,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:47:56,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:47:56,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:47:56,345 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:47:56,356 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:47:56,357 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:47:56,357 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:47:56,357 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1427; bufvoid = 104857600
   [druid] 2018-11-01 17:47:56,357 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 17:47:56,371 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:47:56,384 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2065193994_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:47:56,398 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:47:56,398 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2065193994_0001_m_000000_0' done.
   [druid] 2018-11-01 17:47:56,398 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2065193994_0001_m_000000_0
   [druid] 2018-11-01 17:47:56,398 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2065193994_0001_m_000001_0
   [druid] 2018-11-01 17:47:56,399 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:47:56,400 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:47:56,468 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@17896c89
   [druid] 2018-11-01 17:47:56,471 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 17:47:56,504 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:47:56,504 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:47:56,504 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:47:56,504 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:47:56,504 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:47:56,505 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:47:56,507 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:47:56,507 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:47:56,507 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:47:56,507 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 479; bufvoid = 104857600
   [druid] 2018-11-01 17:47:56,507 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:47:56,515 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:47:56,519 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2065193994_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:47:56,531 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:47:56,532 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2065193994_0001_m_000001_0' done.
   [druid] 2018-11-01 17:47:56,532 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2065193994_0001_m_000001_0
   [druid] 2018-11-01 17:47:56,532 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2065193994_0001_m_000002_0
   [druid] 2018-11-01 17:47:56,533 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:47:56,534 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:47:56,579 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@391b3beb
   [druid] 2018-11-01 17:47:56,582 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 17:47:56,647 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 17:47:56,647 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 17:47:56,647 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 17:47:56,647 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 17:47:56,647 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 17:47:56,648 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 17:47:56,651 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 17:47:56,651 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 17:47:56,651 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 17:47:56,651 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 440; bufvoid = 104857600
   [druid] 2018-11-01 17:47:56,651 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 17:47:56,665 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 17:47:56,669 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2065193994_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:47:56,673 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 17:47:56,673 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2065193994_0001_m_000002_0' done.
   [druid] 2018-11-01 17:47:56,673 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2065193994_0001_m_000002_0
   [druid] 2018-11-01 17:47:56,674 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 17:47:56,678 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 17:47:56,678 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2065193994_0001_r_000000_0
   [druid] 2018-11-01 17:47:56,686 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 17:47:56,687 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 17:47:56,724 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6f40b140
   [druid] 2018-11-01 17:47:56,727 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f29380a
   [druid] 2018-11-01 17:47:56,738 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 17:47:56,741 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local2065193994_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 17:47:56,827 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local2065193994_0001_m_000000_0 decomp: 1441 len: 1445 to MEMORY
   [druid] 2018-11-01 17:47:56,842 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1441 bytes from map-output for attempt_local2065193994_0001_m_000000_0
   [druid] 2018-11-01 17:47:56,845 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1441, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1441
   [druid] 2018-11-01 17:47:56,852 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local2065193994_0001_m_000001_0 decomp: 485 len: 489 to MEMORY
   [druid] 2018-11-01 17:47:56,856 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 485 bytes from map-output for attempt_local2065193994_0001_m_000001_0
   [druid] 2018-11-01 17:47:56,856 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 485, inMemoryMapOutputs.size() -> 2, commitMemory -> 1441, usedMemory ->1926
   [druid] 2018-11-01 17:47:56,864 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local2065193994_0001_m_000002_0 decomp: 446 len: 450 to MEMORY
   [druid] 2018-11-01 17:47:56,866 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 446 bytes from map-output for attempt_local2065193994_0001_m_000002_0
   [druid] 2018-11-01 17:47:56,867 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 446, inMemoryMapOutputs.size() -> 3, commitMemory -> 1926, usedMemory ->2372
   [druid] 2018-11-01 17:47:56,869 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 17:47:56,870 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:47:56,870 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 17:47:56,916 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 17:47:56,916 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 2360 bytes
   [druid] 2018-11-01 17:47:56,921 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 2372 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 17:47:56,924 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 2372 bytes from disk
   [druid] 2018-11-01 17:47:56,924 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 17:47:56,925 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 17:47:56,926 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 2364 bytes
   [druid] 2018-11-01 17:47:56,927 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:47:56,935 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 17:47:56,944 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2065193994_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 17:47:56,946 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 17:47:56,947 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local2065193994_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 17:47:56,950 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local2065193994_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local2065193994_0001_r_000000
   [druid] 2018-11-01 17:47:56,951 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 17:47:56,952 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2065193994_0001_r_000000_0' done.
   [druid] 2018-11-01 17:47:56,952 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2065193994_0001_r_000000_0
   [druid] 2018-11-01 17:47:56,952 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 17:47:57,125 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2065193994_0001 running in uber mode : false
   [druid] 2018-11-01 17:47:57,126 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 17:47:57,127 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2065193994_0001 completed successfully
   [druid] 2018-11-01 17:47:57,159 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=16572
		FILE: Number of bytes written=1156019
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=2346
		Map output materialized bytes=2384
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=2384
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1590165504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=2364
   [druid] 2018-11-01 19:15:21,415 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 19:15:21,418 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 19:15:21,695 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 19:15:21,749 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 19:15:22,156 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 19:15:22,196 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 19:15:22,334 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1030628217_0001
   [druid] 2018-11-01 19:15:22,594 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 19:15:22,595 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1030628217_0001
   [druid] 2018-11-01 19:15:22,607 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 19:15:22,615 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:15:22,619 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 19:15:22,757 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 19:15:22,777 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1030628217_0001_m_000000_0
   [druid] 2018-11-01 19:15:22,810 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:15:22,820 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:15:22,865 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2450acca
   [druid] 2018-11-01 19:15:22,875 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 19:15:22,955 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:15:22,955 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:15:22,955 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:15:22,955 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:15:22,955 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:15:22,958 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:15:23,154 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:15:23,170 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1030628217_0001_m_000001_0
   [druid] 2018-11-01 19:15:23,172 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:15:23,172 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:15:23,215 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3d8bee85
   [druid] 2018-11-01 19:15:23,218 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 19:15:23,280 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:15:23,280 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:15:23,280 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:15:23,280 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:15:23,280 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:15:23,281 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:15:23,284 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:15:23,299 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1030628217_0001_m_000002_0
   [druid] 2018-11-01 19:15:23,301 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:15:23,301 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:15:23,339 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2320732c
   [druid] 2018-11-01 19:15:23,342 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 19:15:23,412 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:15:23,412 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:15:23,412 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:15:23,412 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:15:23,412 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:15:23,413 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:15:23,416 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:15:23,433 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 19:15:23,444 [Thread-6       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1030628217_0001
   java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at mr.LogAnalysis$MyMapper.map(LogAnalysis.java:44)
	at mr.LogAnalysis$MyMapper.map(LogAnalysis.java:18)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[druid] 2018-11-01 19:15:23,598 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1030628217_0001 running in uber mode : false
   [druid] 2018-11-01 19:15:23,600 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-11-01 19:15:23,603 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1030628217_0001 failed with state FAILED due to: NA
   [druid] 2018-11-01 19:15:23,609 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2018-11-01 19:16:51,833 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 19:16:51,835 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 19:16:52,110 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 19:16:52,174 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 19:16:52,367 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 19:16:52,416 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 19:16:52,577 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local462976074_0001
   [druid] 2018-11-01 19:16:52,828 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 19:16:52,831 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local462976074_0001
   [druid] 2018-11-01 19:16:52,839 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 19:16:52,845 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:16:52,849 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 19:16:52,951 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 19:16:52,953 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local462976074_0001_m_000000_0
   [druid] 2018-11-01 19:16:52,987 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:16:52,992 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:16:53,038 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4bd65f40
   [druid] 2018-11-01 19:16:53,047 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 19:16:53,101 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:16:53,101 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:16:53,101 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:16:53,101 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:16:53,101 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:16:53,105 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:16:53,122 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:16:53,123 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:16:53,123 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:16:53,123 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 809; bufvoid = 104857600
   [druid] 2018-11-01 19:16:53,123 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214268(104857072); length = 129/6553600
   [druid] 2018-11-01 19:16:53,138 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:16:53,146 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local462976074_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:16:53,155 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:16:53,155 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local462976074_0001_m_000000_0' done.
   [druid] 2018-11-01 19:16:53,156 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local462976074_0001_m_000000_0
   [druid] 2018-11-01 19:16:53,156 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local462976074_0001_m_000001_0
   [druid] 2018-11-01 19:16:53,157 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:16:53,158 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:16:53,192 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@642efff7
   [druid] 2018-11-01 19:16:53,194 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 19:16:53,224 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:16:53,224 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:16:53,224 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:16:53,224 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:16:53,224 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:16:53,225 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:16:53,228 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:16:53,228 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:16:53,228 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:16:53,228 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 269; bufvoid = 104857600
   [druid] 2018-11-01 19:16:53,228 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214356(104857424); length = 41/6553600
   [druid] 2018-11-01 19:16:53,237 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:16:53,250 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local462976074_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:16:53,263 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:16:53,263 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local462976074_0001_m_000001_0' done.
   [druid] 2018-11-01 19:16:53,263 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local462976074_0001_m_000001_0
   [druid] 2018-11-01 19:16:53,263 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local462976074_0001_m_000002_0
   [druid] 2018-11-01 19:16:53,265 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:16:53,265 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:16:53,313 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5d596a1a
   [druid] 2018-11-01 19:16:53,315 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 19:16:53,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:16:53,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:16:53,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:16:53,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:16:53,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:16:53,366 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:16:53,370 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:16:53,370 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:16:53,370 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:16:53,370 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 271; bufvoid = 104857600
   [druid] 2018-11-01 19:16:53,370 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214356(104857424); length = 41/6553600
   [druid] 2018-11-01 19:16:53,381 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:16:53,387 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local462976074_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:16:53,390 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:16:53,390 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local462976074_0001_m_000002_0' done.
   [druid] 2018-11-01 19:16:53,390 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local462976074_0001_m_000002_0
   [druid] 2018-11-01 19:16:53,395 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 19:16:53,398 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 19:16:53,398 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local462976074_0001_r_000000_0
   [druid] 2018-11-01 19:16:53,406 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:16:53,407 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:16:53,446 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@56b3a80a
   [druid] 2018-11-01 19:16:53,449 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5dd73ae3
   [druid] 2018-11-01 19:16:53,461 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 19:16:53,465 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local462976074_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 19:16:53,521 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local462976074_0001_m_000000_0 decomp: 877 len: 881 to MEMORY
   [druid] 2018-11-01 19:16:53,533 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 877 bytes from map-output for attempt_local462976074_0001_m_000000_0
   [druid] 2018-11-01 19:16:53,537 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 877, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->877
   [druid] 2018-11-01 19:16:53,545 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local462976074_0001_m_000002_0 decomp: 295 len: 299 to MEMORY
   [druid] 2018-11-01 19:16:53,546 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 295 bytes from map-output for attempt_local462976074_0001_m_000002_0
   [druid] 2018-11-01 19:16:53,547 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 295, inMemoryMapOutputs.size() -> 2, commitMemory -> 877, usedMemory ->1172
   [druid] 2018-11-01 19:16:53,552 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local462976074_0001_m_000001_0 decomp: 293 len: 297 to MEMORY
   [druid] 2018-11-01 19:16:53,554 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 293 bytes from map-output for attempt_local462976074_0001_m_000001_0
   [druid] 2018-11-01 19:16:53,554 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 293, inMemoryMapOutputs.size() -> 3, commitMemory -> 1172, usedMemory ->1465
   [druid] 2018-11-01 19:16:53,555 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 19:16:53,556 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:16:53,556 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 19:16:53,571 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 19:16:53,572 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 1459 bytes
   [druid] 2018-11-01 19:16:53,574 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 1465 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 19:16:53,575 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 1465 bytes from disk
   [druid] 2018-11-01 19:16:53,576 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 19:16:53,576 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 19:16:53,579 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1459 bytes
   [druid] 2018-11-01 19:16:53,579 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:16:53,592 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 19:16:53,603 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local462976074_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:16:53,604 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:16:53,604 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local462976074_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 19:16:53,607 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local462976074_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local462976074_0001_r_000000
   [druid] 2018-11-01 19:16:53,609 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 19:16:53,611 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local462976074_0001_r_000000_0' done.
   [druid] 2018-11-01 19:16:53,611 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local462976074_0001_r_000000_0
   [druid] 2018-11-01 19:16:53,611 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 19:16:53,833 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local462976074_0001 running in uber mode : false
   [druid] 2018-11-01 19:16:53,834 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 19:16:53,835 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local462976074_0001 completed successfully
   [druid] 2018-11-01 19:16:53,852 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=14758
		FILE: Number of bytes written=1145095
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=55
		Map output bytes=1349
		Map output materialized bytes=1477
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1477
		Reduce input records=55
		Reduce output records=55
		Spilled Records=110
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1590165504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=1369
   [druid] 2018-11-01 19:23:14,817 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 19:23:14,818 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 19:23:15,185 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 19:23:15,251 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 19:23:15,433 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 19:23:15,476 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 19:23:15,638 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local370485842_0001
   [druid] 2018-11-01 19:23:15,887 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 19:23:15,888 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local370485842_0001
   [druid] 2018-11-01 19:23:15,890 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 19:23:15,896 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:23:15,899 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 19:23:15,982 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 19:23:15,984 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local370485842_0001_m_000000_0
   [druid] 2018-11-01 19:23:16,025 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:23:16,034 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:23:16,088 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@31536e4b
   [druid] 2018-11-01 19:23:16,098 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 19:23:16,172 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:23:16,172 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:23:16,172 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:23:16,173 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:23:16,173 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:23:16,176 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:23:16,192 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:23:16,192 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:23:16,192 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:23:16,192 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 815; bufvoid = 104857600
   [druid] 2018-11-01 19:23:16,193 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 19:23:16,207 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:23:16,215 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local370485842_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:23:16,226 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:23:16,226 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local370485842_0001_m_000000_0' done.
   [druid] 2018-11-01 19:23:16,226 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local370485842_0001_m_000000_0
   [druid] 2018-11-01 19:23:16,226 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local370485842_0001_m_000001_0
   [druid] 2018-11-01 19:23:16,228 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:23:16,228 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:23:16,270 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5d700cd9
   [druid] 2018-11-01 19:23:16,273 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 19:23:16,336 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:23:16,336 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:23:16,336 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:23:16,336 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:23:16,336 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:23:16,337 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:23:16,340 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:23:16,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:23:16,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:23:16,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 271; bufvoid = 104857600
   [druid] 2018-11-01 19:23:16,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 19:23:16,348 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:23:16,356 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local370485842_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:23:16,367 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:23:16,367 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local370485842_0001_m_000001_0' done.
   [druid] 2018-11-01 19:23:16,367 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local370485842_0001_m_000001_0
   [druid] 2018-11-01 19:23:16,368 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local370485842_0001_m_000002_0
   [druid] 2018-11-01 19:23:16,370 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:23:16,371 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:23:16,421 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@ecfc2f5
   [druid] 2018-11-01 19:23:16,424 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 19:23:16,486 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:23:16,486 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:23:16,486 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:23:16,486 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:23:16,486 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:23:16,487 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:23:16,489 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:23:16,489 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:23:16,489 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:23:16,489 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 273; bufvoid = 104857600
   [druid] 2018-11-01 19:23:16,489 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 19:23:16,496 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:23:16,502 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local370485842_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:23:16,505 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:23:16,505 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local370485842_0001_m_000002_0' done.
   [druid] 2018-11-01 19:23:16,505 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local370485842_0001_m_000002_0
   [druid] 2018-11-01 19:23:16,506 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 19:23:16,508 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 19:23:16,509 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local370485842_0001_r_000000_0
   [druid] 2018-11-01 19:23:16,518 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:23:16,519 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:23:16,567 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6a0f1fcc
   [druid] 2018-11-01 19:23:16,572 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@debea5d
   [druid] 2018-11-01 19:23:16,589 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 19:23:16,593 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local370485842_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 19:23:16,666 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local370485842_0001_m_000000_0 decomp: 829 len: 833 to MEMORY
   [druid] 2018-11-01 19:23:16,678 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 829 bytes from map-output for attempt_local370485842_0001_m_000000_0
   [druid] 2018-11-01 19:23:16,680 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 829, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->829
   [druid] 2018-11-01 19:23:16,701 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local370485842_0001_m_000001_0 decomp: 277 len: 281 to MEMORY
   [druid] 2018-11-01 19:23:16,704 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 277 bytes from map-output for attempt_local370485842_0001_m_000001_0
   [druid] 2018-11-01 19:23:16,704 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 277, inMemoryMapOutputs.size() -> 2, commitMemory -> 829, usedMemory ->1106
   [druid] 2018-11-01 19:23:16,708 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local370485842_0001_m_000002_0 decomp: 279 len: 283 to MEMORY
   [druid] 2018-11-01 19:23:16,710 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 279 bytes from map-output for attempt_local370485842_0001_m_000002_0
   [druid] 2018-11-01 19:23:16,710 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 279, inMemoryMapOutputs.size() -> 3, commitMemory -> 1106, usedMemory ->1385
   [druid] 2018-11-01 19:23:16,711 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 19:23:16,712 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:23:16,713 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 19:23:16,728 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 19:23:16,728 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 1373 bytes
   [druid] 2018-11-01 19:23:16,734 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 1385 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 19:23:16,735 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 1385 bytes from disk
   [druid] 2018-11-01 19:23:16,737 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 19:23:16,737 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 19:23:16,739 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1377 bytes
   [druid] 2018-11-01 19:23:16,740 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:23:16,747 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 19:23:16,758 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local370485842_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:23:16,760 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:23:16,760 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local370485842_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 19:23:16,763 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local370485842_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local370485842_0001_r_000000
   [druid] 2018-11-01 19:23:16,768 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 19:23:16,769 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local370485842_0001_r_000000_0' done.
   [druid] 2018-11-01 19:23:16,769 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local370485842_0001_r_000000_0
   [druid] 2018-11-01 19:23:16,770 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 19:23:16,909 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local370485842_0001 running in uber mode : false
   [druid] 2018-11-01 19:23:16,910 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 19:23:16,911 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local370485842_0001 completed successfully
   [druid] 2018-11-01 19:23:16,928 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=14598
		FILE: Number of bytes written=1144743
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=1359
		Map output materialized bytes=1397
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1397
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1455947776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=1369
   [druid] 2018-11-01 19:24:28,326 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 19:24:28,330 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 19:24:28,648 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 19:24:28,722 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 19:24:28,924 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 19:24:28,972 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 19:24:29,129 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1917687904_0001
   [druid] 2018-11-01 19:24:29,342 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 19:24:29,343 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1917687904_0001
   [druid] 2018-11-01 19:24:29,346 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 19:24:29,355 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:24:29,358 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 19:24:29,431 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 19:24:29,432 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1917687904_0001_m_000000_0
   [druid] 2018-11-01 19:24:29,463 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:24:29,471 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:24:29,515 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@43976139
   [druid] 2018-11-01 19:24:29,523 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 19:24:29,571 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:24:29,571 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:24:29,571 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:24:29,571 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:24:29,572 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:24:29,576 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:24:29,594 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:24:29,594 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:24:29,594 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:24:29,594 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 60; bufvoid = 104857600
   [druid] 2018-11-01 19:24:29,594 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 19:24:29,608 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:24:29,615 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1917687904_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:24:29,626 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:24:29,626 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1917687904_0001_m_000000_0' done.
   [druid] 2018-11-01 19:24:29,627 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1917687904_0001_m_000000_0
   [druid] 2018-11-01 19:24:29,628 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1917687904_0001_m_000001_0
   [druid] 2018-11-01 19:24:29,629 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:24:29,631 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:24:29,674 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7382aa7a
   [druid] 2018-11-01 19:24:29,677 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 19:24:29,709 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:24:29,709 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:24:29,709 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:24:29,710 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:24:29,710 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:24:29,710 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:24:29,713 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:24:29,713 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:24:29,713 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:24:29,713 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 20; bufvoid = 104857600
   [druid] 2018-11-01 19:24:29,713 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 19:24:29,721 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:24:29,725 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1917687904_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:24:29,727 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:24:29,728 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1917687904_0001_m_000001_0' done.
   [druid] 2018-11-01 19:24:29,728 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1917687904_0001_m_000001_0
   [druid] 2018-11-01 19:24:29,728 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1917687904_0001_m_000002_0
   [druid] 2018-11-01 19:24:29,729 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:24:29,730 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:24:29,778 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@9a7e00c
   [druid] 2018-11-01 19:24:29,781 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 19:24:29,821 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:24:29,822 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:24:29,822 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:24:29,822 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:24:29,822 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:24:29,822 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:24:29,825 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:24:29,825 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:24:29,825 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:24:29,826 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 20; bufvoid = 104857600
   [druid] 2018-11-01 19:24:29,826 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 19:24:29,839 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:24:29,844 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1917687904_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:24:29,848 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:24:29,848 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1917687904_0001_m_000002_0' done.
   [druid] 2018-11-01 19:24:29,848 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1917687904_0001_m_000002_0
   [druid] 2018-11-01 19:24:29,848 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 19:24:29,851 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 19:24:29,852 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1917687904_0001_r_000000_0
   [druid] 2018-11-01 19:24:29,862 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:24:29,862 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:24:29,906 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3beeb14f
   [druid] 2018-11-01 19:24:29,909 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5957f503
   [druid] 2018-11-01 19:24:29,921 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 19:24:29,924 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1917687904_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 19:24:29,979 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1917687904_0001_m_000001_0 decomp: 24 len: 28 to MEMORY
   [druid] 2018-11-01 19:24:29,988 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 24 bytes from map-output for attempt_local1917687904_0001_m_000001_0
   [druid] 2018-11-01 19:24:29,991 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->24
   [druid] 2018-11-01 19:24:29,998 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1917687904_0001_m_000002_0 decomp: 24 len: 28 to MEMORY
   [druid] 2018-11-01 19:24:29,999 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 24 bytes from map-output for attempt_local1917687904_0001_m_000002_0
   [druid] 2018-11-01 19:24:29,999 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 2, commitMemory -> 24, usedMemory ->48
   [druid] 2018-11-01 19:24:30,004 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1917687904_0001_m_000000_0 decomp: 68 len: 72 to MEMORY
   [druid] 2018-11-01 19:24:30,008 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 68 bytes from map-output for attempt_local1917687904_0001_m_000000_0
   [druid] 2018-11-01 19:24:30,008 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 68, inMemoryMapOutputs.size() -> 3, commitMemory -> 48, usedMemory ->116
   [druid] 2018-11-01 19:24:30,013 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 19:24:30,016 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:24:30,016 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 19:24:30,032 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 19:24:30,033 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 110 bytes
   [druid] 2018-11-01 19:24:30,067 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 116 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 19:24:30,068 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 116 bytes from disk
   [druid] 2018-11-01 19:24:30,070 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 19:24:30,070 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 19:24:30,075 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 110 bytes
   [druid] 2018-11-01 19:24:30,077 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:24:30,154 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 19:24:30,160 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1917687904_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:24:30,161 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:24:30,161 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1917687904_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 19:24:30,163 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1917687904_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local1917687904_0001_r_000000
   [druid] 2018-11-01 19:24:30,164 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 19:24:30,164 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1917687904_0001_r_000000_0' done.
   [druid] 2018-11-01 19:24:30,164 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1917687904_0001_r_000000_0
   [druid] 2018-11-01 19:24:30,164 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 19:24:30,366 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1917687904_0001 running in uber mode : false
   [druid] 2018-11-01 19:24:30,367 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 19:24:30,368 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1917687904_0001 completed successfully
   [druid] 2018-11-01 19:24:30,382 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=12060
		FILE: Number of bytes written=1143792
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=100
		Map output materialized bytes=128
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=128
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1455947776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=112
   [druid] 2018-11-01 19:25:24,339 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-11-01 19:25:24,340 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-11-01 19:25:24,660 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2018-11-01 19:25:24,718 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-11-01 19:25:25,040 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 3
   [druid] 2018-11-01 19:25:25,097 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:3
   [druid] 2018-11-01 19:25:25,293 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1769992505_0001
   [druid] 2018-11-01 19:25:25,507 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-11-01 19:25:25,508 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1769992505_0001
   [druid] 2018-11-01 19:25:25,513 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-11-01 19:25:25,520 [Thread-6       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:25:25,523 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-11-01 19:25:25,626 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-11-01 19:25:25,627 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1769992505_0001_m_000000_0
   [druid] 2018-11-01 19:25:25,663 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:25:25,671 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:25:25,712 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@43976139
   [druid] 2018-11-01 19:25:25,720 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082446366.log:0+1472
   [druid] 2018-11-01 19:25:25,778 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:25:25,778 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:25:25,778 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:25:25,778 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:25:25,778 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:25:25,783 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:25:25,805 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:25:25,805 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:25:25,805 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:25:25,806 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 815; bufvoid = 104857600
   [druid] 2018-11-01 19:25:25,806 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2018-11-01 19:25:25,821 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:25:25,829 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1769992505_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:25:25,839 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:25:25,839 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1769992505_0001_m_000000_0' done.
   [druid] 2018-11-01 19:25:25,839 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1769992505_0001_m_000000_0
   [druid] 2018-11-01 19:25:25,839 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1769992505_0001_m_000001_0
   [druid] 2018-11-01 19:25:25,840 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:25:25,841 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:25:25,885 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7382aa7a
   [druid] 2018-11-01 19:25:25,888 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082494914.log:0+494
   [druid] 2018-11-01 19:25:25,919 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:25:25,919 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:25:25,919 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:25:25,919 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:25:25,919 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:25:25,920 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:25:25,922 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:25:25,923 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:25:25,923 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:25:25,923 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 271; bufvoid = 104857600
   [druid] 2018-11-01 19:25:25,923 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 19:25:25,932 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:25:25,939 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1769992505_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:25:25,955 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:25:25,956 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1769992505_0001_m_000001_0' done.
   [druid] 2018-11-01 19:25:25,956 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1769992505_0001_m_000001_0
   [druid] 2018-11-01 19:25:25,957 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1769992505_0001_m_000002_0
   [druid] 2018-11-01 19:25:25,958 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:25:25,958 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:25:26,012 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@9a7e00c
   [druid] 2018-11-01 19:25:26,015 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/F:/git/InputData/BC-22.1541082381665.log:0+455
   [druid] 2018-11-01 19:25:26,054 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-11-01 19:25:26,054 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-11-01 19:25:26,055 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-11-01 19:25:26,055 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-11-01 19:25:26,055 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-11-01 19:25:26,055 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-11-01 19:25:26,058 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-11-01 19:25:26,059 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-11-01 19:25:26,059 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-11-01 19:25:26,059 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 273; bufvoid = 104857600
   [druid] 2018-11-01 19:25:26,059 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-11-01 19:25:26,069 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-11-01 19:25:26,074 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1769992505_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:25:26,082 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-11-01 19:25:26,082 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1769992505_0001_m_000002_0' done.
   [druid] 2018-11-01 19:25:26,082 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1769992505_0001_m_000002_0
   [druid] 2018-11-01 19:25:26,083 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-11-01 19:25:26,086 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-11-01 19:25:26,086 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1769992505_0001_r_000000_0
   [druid] 2018-11-01 19:25:26,096 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-11-01 19:25:26,097 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-11-01 19:25:26,142 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@402077ca
   [druid] 2018-11-01 19:25:26,146 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5258c282
   [druid] 2018-11-01 19:25:26,164 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1297350656, maxSingleShuffleLimit=324337664, mergeThreshold=856251456, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-11-01 19:25:26,168 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1769992505_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-11-01 19:25:26,244 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1769992505_0001_m_000001_0 decomp: 277 len: 281 to MEMORY
   [druid] 2018-11-01 19:25:26,263 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 277 bytes from map-output for attempt_local1769992505_0001_m_000001_0
   [druid] 2018-11-01 19:25:26,265 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 277, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->277
   [druid] 2018-11-01 19:25:26,272 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1769992505_0001_m_000002_0 decomp: 279 len: 283 to MEMORY
   [druid] 2018-11-01 19:25:26,280 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 279 bytes from map-output for attempt_local1769992505_0001_m_000002_0
   [druid] 2018-11-01 19:25:26,280 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 279, inMemoryMapOutputs.size() -> 2, commitMemory -> 277, usedMemory ->556
   [druid] 2018-11-01 19:25:26,284 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1769992505_0001_m_000000_0 decomp: 829 len: 833 to MEMORY
   [druid] 2018-11-01 19:25:26,287 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 829 bytes from map-output for attempt_local1769992505_0001_m_000000_0
   [druid] 2018-11-01 19:25:26,287 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 829, inMemoryMapOutputs.size() -> 3, commitMemory -> 556, usedMemory ->1385
   [druid] 2018-11-01 19:25:26,288 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-11-01 19:25:26,289 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:25:26,289 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-11-01 19:25:26,315 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 3 sorted segments
   [druid] 2018-11-01 19:25:26,315 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 3 segments left of total size: 1373 bytes
   [druid] 2018-11-01 19:25:26,319 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 3 segments, 1385 bytes to disk to satisfy reduce memory limit
   [druid] 2018-11-01 19:25:26,321 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 1385 bytes from disk
   [druid] 2018-11-01 19:25:26,321 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-11-01 19:25:26,321 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-11-01 19:25:26,323 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1377 bytes
   [druid] 2018-11-01 19:25:26,324 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:25:26,330 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-11-01 19:25:26,338 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1769992505_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-11-01 19:25:26,339 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 3 / 3 copied.
   [druid] 2018-11-01 19:25:26,339 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1769992505_0001_r_000000_0 is allowed to commit now
   [druid] 2018-11-01 19:25:26,345 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1769992505_0001_r_000000_0' to file:/F:/git/LogOut/_temporary/0/task_local1769992505_0001_r_000000
   [druid] 2018-11-01 19:25:26,346 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-11-01 19:25:26,347 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1769992505_0001_r_000000_0' done.
   [druid] 2018-11-01 19:25:26,347 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1769992505_0001_r_000000_0
   [druid] 2018-11-01 19:25:26,347 [Thread-6       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-11-01 19:25:26,511 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1769992505_0001 running in uber mode : false
   [druid] 2018-11-01 19:25:26,512 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-11-01 19:25:26,513 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1769992505_0001 completed successfully
   [druid] 2018-11-01 19:25:26,528 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=14598
		FILE: Number of bytes written=1150631
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=1359
		Map output materialized bytes=1397
		Input split bytes=333
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1397
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1590165504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2421
	File Output Format Counters 
		Bytes Written=1369
   